# Monster Sip Detector 

**Real-time object detection using HSV color segmentation instead of pre-trained models â€” because sometimes the old ways still hit different.**

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![OpenCV](https://img.shields.io/badge/OpenCV-4.11-green.svg)
![MediaPipe](https://img.shields.io/badge/MediaPipe-0.10-orange.svg)

---

## The Idea

<img width="721" height="1292" alt="image" src="https://github.com/user-attachments/assets/ed1b0d95-5c58-4479-82e8-366bcf9c1aa7" />  
<img width="718" height="543" alt="image" src="https://github.com/user-attachments/assets/14ec791b-6882-413a-b18c-de1b2aa051cd" />



I've been getting into color grading while editing videos lately, and spending hours in HSV/HSL color wheels made me realize something: if I can isolate specific colors frame-by-frame for creative edits, why not use the same principles for object detection?

Everyone reaches for YOLO or pre-trained models these days (myself included), but I wanted to see how far traditional computer vision techniques could go. Could I detect a specific object, like the white Monster can I drink while coding, using nothing but color math and clever filtering?

Turns out, **yes**

---

## What It Does

Detects when you take a sip from a Monster Energy can and triggers a video overlay (with sound). The detection pipeline is entirely HSV-based with multi-stage filtering:

```
Webcam Frame
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1: HSV Color Segmentation        â”‚
â”‚  - Isolate white/silver color range     â”‚
â”‚  - Morphological cleanup (open/close)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 2: Shape Filtering               â”‚
â”‚  - Contour area bounds                  â”‚
â”‚  - Aspect ratio (cans are tall)         â”‚
â”‚  - Fill ratio (contour vs bbox)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 3: Texture Verification          â”‚
â”‚  - Dark pixel ratio (logo/text proxy)   â”‚
â”‚  - Edge density via Canny (graphics)    â”‚
â”‚  - Scoring function for best candidate  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 4: Sip Detection                 â”‚
â”‚  - MediaPipe Face Mesh (mouth tracking) â”‚
â”‚  - Euclidean distance: can â†’ mouth      â”‚
â”‚  - Proximity threshold trigger          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“
 Video + Audio Playback ðŸŽ¬
```

---

## Why Not Just Use YOLO?

Good question. YOLO would probably work out of the box. But:

1. **Learning** â€” I wanted to actually understand what's happening under the hood instead of treating models as black boxes
2. **Lightweight** â€” No model weights to download, no GPU required, runs smooth on any machine
3. **Customizable** â€” Every parameter is tunable in real-time via the calibration tool
4. **The Challenge** â€” Constraints breed creativity. Turns out a white can in a messy room is a hard problem when you can't just throw a neural net at it

The texture verification stage (dark pixels + edge density) was the key insight â€” it filters out random white objects by checking if the region actually *looks* like a printed can.

---

## Demo

The app tracks the can, tracks your mouth via MediaPipe, calculates the distance between them, and triggers when you take a sip:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FPS: 32.5                              â”‚
â”‚  Can: DETECTED                          â”‚
â”‚  Mouth: OPEN                            â”‚
â”‚  Sips: 3                                â”‚
â”‚                                         â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚            â”‚ MONSTER  â”‚â†â”€ Can bbox      â”‚
â”‚            â”‚   CAN    â”‚                 â”‚
â”‚            â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                 â”‚                       â”‚
â”‚              257px â†â”€ Distance          â”‚
â”‚                 â”‚                       â”‚
â”‚                 â—¯ â†â”€ Mouth position     â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Installation

```bash
git clone https://github.com/yourusername/monster-sip-detector.git
cd monster-sip-detector

pip install -r requirements.txt
```

### Dependencies
```
opencv-python==4.11.0
mediapipe==0.10.21
numpy==1.26.4
pygame>=2.5.0
```

---

## Usage

### Run the Detector
```bash
python monster_sip_detector.py
```

### Calibrate for Your Environment
The calibration tool is crucial â€” lighting conditions vary, and you'll need to tune the HSV range and texture filters for your setup:

```bash
python calibrate_hsv.py
```

This opens a multi-window interface with **17 trackbars** for real-time tuning:
- HSV range (H/S/V min & max)
- Area bounds
- Aspect ratio
- Fill ratio
- Dark pixel threshold & percentage
- Canny edge thresholds
- Morphology kernel size

Press `S` to save your calibration to `config.json`.

### Keyboard Controls

| Key | Action |
|-----|--------|
| `Q` | Quit |
| `D` | Toggle debug overlay |
| `M` | Toggle HSV mask view |
| `R` | Reset sip counter |
| `T` | Manual trigger (testing) |
| `F` | Freeze frame (calibrator) |
| `S` | Save config (calibrator) |

---

## Configuration

All parameters live in `config.json`:

```json
{
    "can_hsv_lower": [76, 0, 0],
    "can_hsv_upper": [180, 40, 230],
    "min_can_area": 125,
    "max_can_area": 9988,
    "min_aspect_ratio": 1.25,
    "max_aspect_ratio": 8.0,
    "min_fill_pct": 0,
    "dark_thresh": 255,
    "min_dark_pct": 27,
    "min_edge_pct": 12,
    "sip_distance_threshold": 150,
    "sip_cooldown": 3.0
}
```

---

## Adding Your Own Video

Drop your video in the `assets/` folder and update the config:

```json
{
    "video_path": "assets/your_video.mp4",
    "audio_path": "assets/your_audio.mp3"
}
```

The video plays with synced audio when a sip is detected.

---

## Project Structure

```
monster-sip-detector/
â”œâ”€â”€ monster_sip_detector.py  # Main application
â”œâ”€â”€ calibrate_hsv.py         # Calibration tool (17 trackbars)
â”œâ”€â”€ config.json              # All tunable parameters
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ flex_video.mp4       # Triggered video
â”‚   â””â”€â”€ your_audio.mp3       # Audio track
â””â”€â”€ README.md
```

---

## What I Learned

- HSV is surprisingly powerful when you layer multiple verification stages
- The hardest part wasn't detection â€” it was *rejection* of false positives
- Texture analysis (dark pixels + edges) is a simple but effective way to distinguish "printed object" from "random white thing"
- MediaPipe Face Mesh is incredible for the price (free)
- Sometimes skipping the obvious solution (YOLO) forces you to learn more

---

## Tech Stack

- **OpenCV** â€” Image processing, HSV segmentation, morphology, Canny edges
- **MediaPipe** â€” Face Mesh for mouth landmark tracking
- **NumPy** â€” Array operations
- **Pygame** â€” Audio playback

---

## License

MIT â€” do whatever you want with it.

---
